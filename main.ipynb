{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте вы выполните комплексное домашнее задание по подготовке, оптимизации и развертыванию модели машинного обучения с использованием современных инструментов. Цель проекта – освоить процессы обучения, конвертации, оптимизации и интеграции моделей в продакшн-среду с применением Triton Inference Server, Docker и микросервисной архитектуры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx==1.13.1 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: onnxruntime==1.14.1 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnx==1.13.1) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnx==1.13.1) (4.12.2)\n",
      "Requirement already satisfied: coloredlogs in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnxruntime==1.14.1) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnxruntime==1.14.1) (24.12.23)\n",
      "Requirement already satisfied: packaging in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnxruntime==1.14.1) (24.2)\n",
      "Requirement already satisfied: sympy in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnxruntime==1.14.1) (1.13.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime==1.14.1) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from sympy->onnxruntime==1.14.1) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install onnx==1.13.1 onnxruntime==1.14.1 numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxoptimizer in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: onnx in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnxoptimizer) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnx->onnxoptimizer) (1.26.4)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnx->onnxoptimizer) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /Users/dmitrii.kolpakov/Downloads/.venv/lib/python3.10/site-packages (from onnx->onnxoptimizer) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install onnxoptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Обучение модели**\n",
    "   - Обучите самописную модель на базе **Torch** или **TensorFlow**.\n",
    "   - Используйте стандартные слои, избегая кастомных решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.ao.quantization as quantization\n",
    "import torch.onnx\n",
    "import onnxoptimizer\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Среднее и стандартное отклонение MNIST\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU() \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc = nn.Linear(64 * 28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}] Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Получаем индекс максимального логита\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "MODEL_NAME = \"pytorch.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000] Loss: 2.300770\n",
      "Train Epoch: 1 [6400/60000] Loss: 0.240952\n",
      "Train Epoch: 1 [12800/60000] Loss: 0.137812\n",
      "Train Epoch: 1 [19200/60000] Loss: 0.217435\n",
      "Train Epoch: 1 [25600/60000] Loss: 0.233539\n",
      "Train Epoch: 1 [32000/60000] Loss: 0.041848\n",
      "Train Epoch: 1 [38400/60000] Loss: 0.032779\n",
      "Train Epoch: 1 [44800/60000] Loss: 0.074851\n",
      "Train Epoch: 1 [51200/60000] Loss: 0.030709\n",
      "Train Epoch: 1 [57600/60000] Loss: 0.040874\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9842/10000 (98.42%)\n",
      "\n",
      "Train Epoch: 2 [0/60000] Loss: 0.114845\n",
      "Train Epoch: 2 [6400/60000] Loss: 0.054702\n",
      "Train Epoch: 2 [12800/60000] Loss: 0.114300\n",
      "Train Epoch: 2 [19200/60000] Loss: 0.020022\n",
      "Train Epoch: 2 [25600/60000] Loss: 0.037703\n",
      "Train Epoch: 2 [32000/60000] Loss: 0.101201\n",
      "Train Epoch: 2 [38400/60000] Loss: 0.026494\n",
      "Train Epoch: 2 [44800/60000] Loss: 0.060995\n",
      "Train Epoch: 2 [51200/60000] Loss: 0.029231\n",
      "Train Epoch: 2 [57600/60000] Loss: 0.018492\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 9857/10000 (98.57%)\n",
      "\n",
      "Train Epoch: 3 [0/60000] Loss: 0.007395\n",
      "Train Epoch: 3 [6400/60000] Loss: 0.005126\n",
      "Train Epoch: 3 [12800/60000] Loss: 0.001634\n",
      "Train Epoch: 3 [19200/60000] Loss: 0.015078\n",
      "Train Epoch: 3 [25600/60000] Loss: 0.010593\n",
      "Train Epoch: 3 [32000/60000] Loss: 0.025622\n",
      "Train Epoch: 3 [38400/60000] Loss: 0.000480\n",
      "Train Epoch: 3 [44800/60000] Loss: 0.239464\n",
      "Train Epoch: 3 [51200/60000] Loss: 0.004057\n",
      "Train Epoch: 3 [57600/60000] Loss: 0.022703\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9848/10000 (98.48%)\n",
      "\n",
      "Train Epoch: 4 [0/60000] Loss: 0.010900\n",
      "Train Epoch: 4 [6400/60000] Loss: 0.012306\n",
      "Train Epoch: 4 [12800/60000] Loss: 0.008657\n",
      "Train Epoch: 4 [19200/60000] Loss: 0.004781\n",
      "Train Epoch: 4 [25600/60000] Loss: 0.019837\n",
      "Train Epoch: 4 [32000/60000] Loss: 0.002622\n",
      "Train Epoch: 4 [38400/60000] Loss: 0.001343\n",
      "Train Epoch: 4 [44800/60000] Loss: 0.014825\n",
      "Train Epoch: 4 [51200/60000] Loss: 0.017691\n",
      "Train Epoch: 4 [57600/60000] Loss: 0.001017\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9838/10000 (98.38%)\n",
      "\n",
      "Train Epoch: 5 [0/60000] Loss: 0.001209\n",
      "Train Epoch: 5 [6400/60000] Loss: 0.003514\n",
      "Train Epoch: 5 [12800/60000] Loss: 0.009804\n",
      "Train Epoch: 5 [19200/60000] Loss: 0.000903\n",
      "Train Epoch: 5 [25600/60000] Loss: 0.006301\n",
      "Train Epoch: 5 [32000/60000] Loss: 0.014116\n",
      "Train Epoch: 5 [38400/60000] Loss: 0.000834\n",
      "Train Epoch: 5 [44800/60000] Loss: 0.082507\n",
      "Train Epoch: 5 [51200/60000] Loss: 0.000080\n",
      "Train Epoch: 5 [57600/60000] Loss: 0.034072\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9845/10000 (98.45%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, criterion, epoch)\n",
    "    test(model, test_loader, criterion)\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN() \n",
    "model.load_state_dict(torch.load(MODEL_NAME))\n",
    "model.eval()\n",
    "\n",
    "traced_model = torch.jit.trace(model, torch.randn(1, 1, 28, 28))\n",
    "\n",
    "traced_model.save(\"pytorch.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Конвертация в ONNX**\n",
    "   - Экспортируйте обученную модель в формат **ONNX**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN() \n",
    "model.load_state_dict(torch.load(MODEL_NAME))\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "onnx_filename = \"onnx.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,  \n",
    "    dummy_input,\n",
    "    onnx_filename,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"], \n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}, \n",
    "    opset_version=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"onnx.onnx\")\n",
    "onnx.checker.check_model(onnx_model)  # Проверяем модель\n",
    "\n",
    "ort_session = ort.InferenceSession(\"onnx.onnx\")\n",
    "\n",
    "x = np.random.randn(1, 1, 28, 28).astype(np.float32)\n",
    "ort_inputs = {\"input\": x}\n",
    "ort_outs = ort_session.run([\"output\"], ort_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **(Опционально) Конвертация в TensorRT (TRT)**\n",
    "   - При необходимости, конвертируйте модель в формат **TensorRT** для повышения производительности инференса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Оптимизация модели средствами Torch/TensorFlow**\n",
    "   - Примените встроенные методы оптимизации (например, quantization или pruning) для улучшения эффективности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.quantized.engine = 'qnnpack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"pytorch.pth\"))\n",
    "model.eval()\n",
    "\n",
    "model.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
    "model_fused = torch.ao.quantization.fuse_modules(model, [['conv1', 'relu1'], ['conv2', 'relu2']])\n",
    "model_prepared = torch.ao.quantization.prepare(model_fused)\n",
    "model_int8 = torch.ao.quantization.convert(model_prepared)\n",
    "\n",
    "scripted_model = torch.jit.script(model_int8)\n",
    "scripted_model.save(\"pytorch_optimized.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"pytorch.pth\"))\n",
    "model.eval()\n",
    "\n",
    "model.qconfig = quantization.QConfig(\n",
    "    activation=quantization.default_observer,\n",
    "    weight=quantization.default_weight_observer\n",
    ")\n",
    "\n",
    "model_fused = torch.ao.quantization.fuse_modules(model, [['conv1', 'relu1'], ['conv2', 'relu2']])\n",
    "model_prepared = torch.ao.quantization.prepare(model_fused)\n",
    "model_int8 = torch.ao.quantization.convert(model_prepared)\n",
    "\n",
    "scripted_model = torch.jit.script(model_int8)\n",
    "scripted_model.save(\"pytorch_quantized.pt\")  # TorchScript-модель\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Оптимизация модели инструментами ONNX и (опционально) TRT**\n",
    "   - Используйте оптимизирующие инструменты для ONNX (например, ONNX Runtime) для повышения производительности.\n",
    "   - (Опционально) Оптимизируйте модель в формате TensorRT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-17.818356, -14.739766,  -6.881494, -10.863028, -15.319208,\n",
       "          -9.028692, -13.222997,  -8.228025,  -8.828684, -11.138251]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model_path = \"onnx.onnx\"\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "passes = [\n",
    "    \"eliminate_deadend\",        # Убирает ненужные узлы\n",
    "    \"eliminate_identity\",       # Убирает операции типа Identity\n",
    "    \"eliminate_nop_transpose\",  # Убирает ненужные транспонирования\n",
    "    \"fuse_bn_into_conv\",        # Сливает BatchNorm в Conv2d\n",
    "    \"fuse_add_bias_into_conv\"   # Сливает Add в Conv2d\n",
    "]\n",
    "\n",
    "optimized_model = onnxoptimizer.optimize(onnx_model, passes)\n",
    "optimized_onnx_path = \"onnx_optimized.onnx\"\n",
    "\n",
    "onnx.save(optimized_model, optimized_onnx_path)\n",
    "\n",
    "ort_session = ort.InferenceSession(optimized_onnx_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "x = np.random.randn(1, 1, 28, 28).astype(np.float32)  # MNIST вход\n",
    "\n",
    "# Выполняем инференс\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: x}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "ort_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
